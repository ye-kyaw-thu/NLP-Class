\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{fontspec}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{array}

%for typing Myanmar text, you can also used with Myanmar3 font
\newfontfamily {\padauktext}[Script=Myanmar]{Padauk}
%\newfontinstance {\padauktext}[Script=Myanmar]{Padauk}

%for double quote
\newcommand{\quotes}[1]{``#1''}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Statistical Machine Translation between Myanmar Sign Language and Myanmar SignWriting\\
%{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and
%should not be used}
%\thanks{Identify applicable funding agency here. If none, delete this.}
}

%%%%%%%% for review process %%%%%%%%%%

\author{\IEEEauthorblockN{1\textsuperscript{st} Author A}
\IEEEauthorblockA{\textit{University A, }} \\
City, Country\\
{authora@univa.com}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Author B}
\IEEEauthorblockA{\textit{University B,}\\ City, Country \\
\textit{University X,}\\ City, Country\\
authorb@gmail.com}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Author C}
\IEEEauthorblockA{\textit{University A, } \\
City, Country \\
authorc@univa.com}
\and
\IEEEauthorblockN{4\textsuperscript{th} Author D}
\IEEEauthorblockA{\textit{University A, } \\
City, Country \\
authord@univa.com}
\and
\IEEEauthorblockN{5\textsuperscript{th} Author E}
\IEEEauthorblockA{\textit{University C,} \\
City, Country \\
authore@univc.com}
\and
\IEEEauthorblockN{6\textsuperscript{th} Author F}
\IEEEauthorblockA{\textit{University A, } \\
City, Country\\
authorf@univa.com}
\and
\IEEEauthorblockN{7\textsuperscript{th} Author G}
\IEEEauthorblockA{\textit{University A, } \\
City, Country\\
authorg@univa.com}
}


%%%%%%%%%%%%%%%%%%%%%%%

\author{\IEEEauthorblockN{1\textsuperscript{st} Hnin Wai Wai Hlaing}, {3\textsuperscript{rd} Swe Zin Moe}, {4\textsuperscript{th} Hlaing Myat Nwe}, {6\textsuperscript{th} Nandar Win Min}, {7\textsuperscript{th} Hnin Aye Thant}}
\IEEEauthorblockA{\textit{University of Technology (Yatanarpon Cyber City)} \\
\textit{name of organization (of Aff.)}\\
Pyin Oo Lwin, Myanmar \\
{hninwaiwaihlaing.ycc, swezinmoe.1011, hlaingmyatnwe.nwe, nandarwinmin, hninayethant}\@gmail.com}}

%\author{\IEEEauthorblockN{1\textsuperscript{st} Hnin Wai Wai Hlaing}
%\IEEEauthorblockA{\textit{University of Technology (Yatanarpon Cyber City), UTYCC, }} \\
%\textit{name of organization (of Aff.)}\\
%Pyin Oo Lwin, Myanmar\\
%{hninwaiwaihlaing.ycc@gmail.com}
%\and
%\IEEEauthorblockN{2\textsuperscript{nd} Ye Kyaw Thu}
%\IEEEauthorblockA{\textit{Okayama Prefectural University, OPU,}\\ Okayama, Japan \\
%\textit{Waseda University,}\\ Tokyo, Japan\\
%wasedakuma@gmail.com}
%\and
%\IEEEauthorblockN{3\textsuperscript{rd} Swe Zin Moe}
%\IEEEauthorblockA{\textit{University of Technology (Yatanarpon Cyber City), UTYCC, } \\
%Pyin Oo Lwin, Myanmar \\
%swezinmoe.1011@gmail.com}
%\and
%\IEEEauthorblockN{4\textsuperscript{th} Hlaing Myat Nwe}
%\IEEEauthorblockA{\textit{University of Technology (Yatanarpon Cyber City), UTYCC, } \\
%Pyin Oo Lwin, Myanmar \\
%hlaingmyatnwe.nwe@gmail.com}
%\and
%\IEEEauthorblockN{5\textsuperscript{th} Ni Htwe Aung}
%\IEEEauthorblockA{\textit{Yangon Technological University, YTU, } \\
%Yangon, Myanmar \\
%nhadec@gmail.com}
%\and
%\IEEEauthorblockN{6\textsuperscript{th} Nandar Win Min}
%\IEEEauthorblockA{\textit{University of Technology (Yatanarpon Cyber City), UTYCC, } \\
%Pyin Oo Lwin, Myanmar\\
%nandarwinmin@gmail.com}
%\and
%\IEEEauthorblockN{7\textsuperscript{th} Hnin Aye Thant}
%\IEEEauthorblockA{\textit{University of Technology (Yatanarpon Cyber City), UTYCC, } \\
%Pyin Oo Lwin, Myanmar\\
%hninayethant@gmail.com}
%}

\maketitle

\begin{abstract}
This paper contributes the first evaluation of automatic machine translation between Myanmar Sign Language (MSL) and Myanmar SignWriting (MSW). The main motivation is to introduce SignWriting to the Myanmar Deaf society with the help of statistical machine translation. In this paper, we use our MSL-MSW corpus for general domain that contains a textual representation of MSL and its equivalent Myanmar SignWriting. The methods studied in this work were phrase-based, hierarchical phrase-based, the operation sequence model. In addition, two different segmentation schemes were studies, these were syllable segmentation and word segmentation for MSL. The performance of the machine translation systems was automatically measured in terms of BLEU and RIBES for all experiments. Our main findings were that operation sequence model method gave the highest scores (37.54 BLEU and 0.8280 RIBES) for MSL to MSW translation and hierarchical phrase based machine translation gave the highest scores (52.79 BLEU and 0.8756 RIBES) for MSW to MSL translation. Generally, translation with word segmented MSL achieved better performance than syllable segmentation of MSL. Our 10-fold cross validation results produced promising results even with the limited training data and we expect this can be developed into a useful machine translation system as more data becomes available in the future. 

\end{abstract}

\begin{IEEEkeywords}
Machine Translation, Hierarchical Phrase-based Machine Translation (HPBSMT), Myanmar Sign Language (MSL), Myanmar SignWriting (MSW), Operation Sequence Model (OSM), Phrase-based Machine Translation (PBSMT)
\end{IEEEkeywords}

\section{Introduction}
\label{sec:intro}

As reported by the 2014 Myanmar national census, about 1.3 percent of the populations in Myanmar are deaf or hard-of-hearing \cite{census_2014}. Myanmar Sign Language (MSL) is used as a primary communication language among Deaf people. They face various difficulties in communicating with other hearing people and feel isolating from their surroundings because they are limited resources of information written in their language. The main reasons for this problem are lack of literature written with Deaf sign language that can be understood by Deaf people. Most of the Myanmar Deaf people are difficult to read or write the standard Myanmar written language because the grammar structure and usage of Myanmar written language and Myanmar sign language are not the same. Additionally, Myanmar language is a tonal and syllable-based. For these reasons, we wish to break down the language barrier and able to get better communication between hearing-impaired and normal-hearing people. Our first motivation is studying statistical machine translation methodologies between textual representation of Myanmar sign language and SignWriting. In other words, this research is developing SignWriting for Myanmar sign language. From this research, we are expacting Deaf people who can understand Myanmar Sign Language can start learning SignWriting and develop various written resources of current Myanmar sign language such as MSL-MSW dictionary, MSW educational textbooks. 

This paper contributes the first evaluation of automatic machine translation between MSL and MSW in both directions. One more contribution is we are developing a parallel corpus of MSL-MSW on the general domain. In this experiment, we used the current version of the MSL-MSW corpus relating to general domain. 

The structure of the paper is as follows. In the next section, we present a brief review of machine translation systems for sign languages including SignWritng. Section~\ref{sec:SL} presents a sketch of MSL and common phenomena of many other SLs. Section~\ref{sec:SW} introduce SignWriting and Section~\ref{sec:corpusPreparation} presents the MSL-MSW parallel corpus preparation for machine translation experiments. In Section~\ref{sec:experimentalMethodology}, we describe the methodologies used in the machine translation experiments. Section~\ref{sec:experiments} presents statistical information of the corpus and the experimental settings. The results together with some discussions are presented in Section~\ref{resultAndDiscussion}. Section~\ref{sec:errorAnalysis}  presents the error analysis on translated outputs. Final Section~\ref{sec:conclusion} concludes our works and indicates promising results for future research.

\section{Machine Translation for Sign Language}
\label{sec:MT4SL}

Machine translation is an application of computers to translate from one natural language to other languages that convey the meaning of the original source language. An automated sign language machine translation is in great demand to make more information and services accessible to persons with hearing and speaking disabilities on a more economical basis when an interpreter is unavailable.

MT systems between spoken and sign languages had a start in the late 90s. Strategies used for developing MT system are also used for developing text to sign language MT system including direct MT, template-based MT, transfer-based MT, interlingua-based MT, rule-based MT, syntax-based MT and statistical-based MT. Details of each strategy can be found in several books as follows: Hutchins and Somers, 1992 \cite{Hutchins_1992}; Hutchins, 2000 \cite{Hutchins_2000}; Nirenburg and Raskin, 2004 \cite{Nirenburg_2004}. A number of sign language machine translation systems have been carried out around the world, e.g. TESSA system (Bangham \& Cox, 2000) \cite{Bangham_2000}, weather reports generate system (Angus \& Smith, 1999) \cite{Angus_1999}, South African sign language machine translation system (Zijl \& Barker, 2003) \cite{Zijl_2003}, experiments in sign language machine translation using examples (Morrissey \& Way, 2006) \cite{Morrissey_2006}, Morpho-syntax base statistical methods for automatic sign language translation (Stein, Bungeroth, \& Ney, 2006) \cite{Stein_2006}, Arabic Text-to-SignWriting Translation (Almasoud \& Al-Khalifa, 2012) \cite{Almasoud_2012}.

\section{Sign Language}
\label{sec:SL}

Sign Language is the native language of the Deaf community. As spoken language use throat, nose and mouth as articulators, they can express their needs and the formation of concepts by combining hand shapes, orientation and movement of the hands, arms or body and facial expressions. Wherever vocal communication is impossible, sign language can be used as a language barrier among Deaf people.

However, SLs are not at all uniform according to the culture and environments. It is not clear how many SLs there are. Each country has its own native sign language and some have more than one. Although SL differs in different regions, it mainly depends on the basic parts of sign. SL means the combination of Manual Features (MFs) and Non-Manual Features (NMFs). Fig.~\ref{fig:structure_SL} shows the structure of sign language. 

Manual features are signs formed by one or both hands in different shapes, locations, movements and orientations to express meanings. Non-manual features contain various facial expressions, head tilting, and shoulder raising, mouthing and similar signals that add to hand sign to describe meanings. And then, it grammatically includes questions, negation, relative clause, boundaries between sentences and arguments structure of some verbs \cite{Thompson_2006}. Similar to American Sign Language (ASL) and British Sign Language (BSL), Myanmar Sign Language use non-manual marking for yes/no questions. They are shown through raised eyebrows and a forward head tilt \cite{Baker1980}, \cite{Sutton_1998}, \cite{MSL_conversation_2009}. Fig.~\ref{fig:non_manual_features} shows an example of MSL sentence \quotes{{\padauktext အပူချိန် ဒီဂရီ ဘယ်လောက်လဲ ။}} + “NMFs –chin up and raised an eyebrows for wh-question”. The meaning of the MSL sentence is \quotes{{\padauktext အပူချိန် ဘယ်လောက်လဲ ။}} in Myanmar language and “What is the temperature?”  in English respectively. 

\begin{figure}[htbp]
\centerline{\includegraphics[angle=-89.99, width=0.5\textwidth]{./fig/manual-and-non-manual-feature.pdf}}
%\centerline{\includegraphics[scale=0.25]{./fig/manual-and-non-manual-feature.pdf}}
%\centerline{\includegraphics[width=0.5\textwidth, height=1in]{./fig/manual-and-non-manual-feature.pdf}}
\caption{The structure of sign language}
\label{fig:structure_SL}
\end{figure}

\begin{figure}[htbp]
%\begin{figure*}[t!]
%\centerline{\includegraphics[width=\textwidth]{./fig/signmaker_editor.pdf}}
\centerline{\includegraphics[angle=-89.99, width=0.5\textwidth]{./fig/what-is-the-temperature.pdf}}
%\centerline{\includegraphics[width=0.5\textwidth, height=1in]{./fig/what-is-the-temperature.pdf}}
\caption{An example of MSL sentence that used non-manual features (from Myanmar Sign Language Basic Conversation Book)}
\label{fig:non_manual_features}
\end{figure}

\section{SignWriting}
\label{sec:SW}

There are many writing systems to represent sign languages in written form in other countries such as Gloss Notation, Hamburg Notation System (HamNoSys) and SignWriting. Among them, SignWriting is becoming widespread because it is language independent, which contain a large number of basic symbols. SignWriting was proposed in 1974 by Valerie Sutton. At first, she is trying to note all dance, all mime and gesture. It is also called movement-writing system for writing all dance, all sports, and all movement. Nowadays, it is becoming SignWriting for Deaf communities. It uses a combination of iconic symbols and the shapes of characters, that are abstract pictures of the hand, body, face and so on \cite{SW_hp}. International SignWriting Alphabet (ISWA) 2010 defines 7 categories, 30 groups of symbols to form 652 base symbols and 35,023 symbols. Fig~\ref{fig:7_categories_SW} shows seven categories of ISWA.

\begin{figure}[htbp]
\centerline{\includegraphics[width=0.4\textwidth]{./fig/7-cate-SignWriting.pdf}}
\caption{Seven categories of International SignWriting Alphabet (ISWA), (from the book of \quotes{SignWriting Hand Symbols in the International SignWriting Alphabet 2010})}
\label{fig:7_categories_SW}
\end{figure}

Seven categories of ISWA include hand, movement, dynamic and timing, head and face, body, detailed location, and punctuation. It also represents the sign symbols from both signer’s point of view and observer’s point of view. However, almost all publications used the signer’s point of view and denote the right hand is dominant. These symbols can be arranged both horizontally (left-to-right) and vertically (top-to-bottom), and can be rotated in 8 directions. The orientation of the palm is indicated by filling the glyphs for the hand shape. A white glyph indicates that one is facing the palm of the hand; a black glyph indicates that one is facing the back of the hand and half-shading indicates that one is seeing the hands from the side \cite{SW_manual_2010}. Hand orientation is important for SignWriting and there are 3 different filling symbols (see Fig.~\ref{fig:3-filling-symbols}) and 16 different spatial rotations symbols (see Fig.~\ref{fig:16-rotation-symbols}). SignWriting is the first writing system for sign languages to be included in the Unicode Standard (U+1D800 to U+1DAAF) \cite{SW_unicode}. The Unicode block for SignWriting is U+1D84C (signwriting hand-flat five fingers spread)-U+1DA9C (signwriting fill modifier-3), which represents five fingers spread seeing the back of the hand from the signer’s point of view. 

% SignWriting is U+1D84C-U+1DA9C

\begin{figure}
\centering
\begin{subfigure}[a]{0.18\textwidth}
   \includegraphics[width=1\linewidth]{./fig/3-different-filling-symbols.pdf}
   \caption{}
   \label{fig:3-filling-symbols} 
\end{subfigure}

\begin{subfigure}[b]{0.35\textwidth}
   \includegraphics[width=1\linewidth]{./fig/16-rotation-symbols.pdf}
   \caption{}
   \label{fig:16-rotation-symbols}
\end{subfigure}

\caption[SignWriting symbols for hand orientation]{(a) three different filling symbols (b) sixteen different spatial rotation symbols}
\end{figure}

\section {Corpus Preparation}
\label{sec:corpusPreparation}

Myanmar NLP researchers are facing with many difficulties arising from the lack of resources; in particular parallel corpora are scare \cite{Ye_PACLIN_2015}. Currently, there is no parallel corpus for MSL-MSW. Therefore, as a first step, we are building a multimedia parallel MSL corpus with the purpose of developing a Machine Translation (MT)-based approach for using technology to assist hearing and speaking disabilities with limited Myanmar language in their daily life basic conversation.

In this section, we will explain all the development steps in the construction of MSL-MSW corpus for general domain. 

%for camera-ready version:
%https://github.com/ye-kyaw-thu/MSL4Emergency

\subsection {Data Collection}
\label{subsec:DataCollection}

The spoken and the written style sentences are manually selected from several Myanmar language books including sign language dictionary. The domain is a general domain, the corpus developing is work in progress and we used 1,448 sentences in this experiment. It contains two main categories and they are emergency for fire, earthquake, floods, storms, accident, police and health and basic conversation for greeting, travelling, occupations, number, date and time.The raw Myanmar sentences to MSL translation was done by discussions with Sign language trainers, native signers and deaf persons to ensure the meaning of the original Myanmar written sentences. After making several discussions, sign language video data are collected for each Myanmar sentence. 

This corpus was developed with 22 sign language trainers and Deaf people: males and females, age range from 11 to 48, from School for the Deaf (Mandalay), Mary Chapman School for Deaf Children (Yangon), School for the Deaf (Tarmwe), Myanmar Deaf Society and Literacy and Language Development for the Deaf in Yangon and Mandalay regions has been carried out. The MSL-MSW corpus contains MSL videos, a textual representation or direct annotation of Myanmar sign language with Myanmar language and parallel SignWriting symbols.

\subsection {Manual Annotation with SignWriting}
\label{subsec:annotation}

After video data collection had been finished, we have to define SignWriting symbols for each sign of MSL. In details, we watched the recorded video several times for defining both manual and non-manual signs. After that, sign symbols are placed on the canvus of SignMaker to form the shape and movement of signs. SignWriting symbols are needed to arrange in a unique sequence. Fig.~\ref{signmaker_editor} shows the sign symbols arrangement in SignMaker. There are two ways to prepare SignWriting data: one is the formal SignWriting–based on 2-dimensional mathematics and written as a string of ASCII characters and another is Unicode representation of SignWriting symbols. In our work, we use Unicode numbers for SignWriting symbols seeing SignWriting symbols arrangement in SignMaker. An example of SignWriting Unicode character sequences for the MSW word \quotes{doctor} is as follows and equivalent MSW can be seen in Fig.~\ref{signmaker_editor}. \\

\noindent
English: Doctor \\
Myanmar: {\padauktext ဆရာဝန်} \\
Unicode Block: \quotes{\textbackslash U1D800\textbackslash U1DAAA\textbackslash U1D800\textbackslash U1DA9C\\ \textbackslash U1D80A\textbackslash U1DA9B\textbackslash U1DAA8\textbackslash U1D9FF\textbackslash U1DA30\\\textbackslash U1D80A\textbackslash U1DA9B}\\

%SignWriting Representation: 

%\begin{figure}[h!]
%\centerline{\includegraphics[width=1.8in, height=0.5in]{./fig/doctor-sw.pdf}}
%\captionsetup{labelformat=empty}
%\caption{SignWriting for the word "medical doctor"}
%\label{doctorSW}
%\end{figure}

%\begin{figure}[htbp]
\begin{figure*}[t!]
%\centerline{\includegraphics[width=\textwidth]{./fig/signmaker_editor.pdf}}
\centerline{\includegraphics[width=0.8\textwidth]{./fig/signmaker_editor.pdf}}
\caption{An example of sign symbol sequence arrangement in the SignMaker 2017}
\label{signmaker_editor}
\end{figure*}

\subsection{Syllable and Word Segmentation}
\label{subsec:syllableWordSeg}

In SMT, word segmentation is a necessary step in order to yield a set of tokens upon which the alignment and indeed the whole machine learning process can operate. We did sign unit based word segmentation for both text representation of MSL and MSW. Sign unit based word segmentation was done manually for the whole parallel corpus. It is based on meaningful MSL words considering repeated signs (e.g. two or more repeated \quotes{thank you} sign for \quotes{please}), sign with multiple meanings (e.g. one MSL sign for \quotes{blood} and \quotes{red}), compound sign (e.g. combination of MSL signs \quotes{car}, \quotes{emergency} and \quotes{fire extinguishing} for \quotes{fire truck}, name sign (e.g. Yangon city), fingerspelling sign, fingerspelling shortcut sign (Myanmar consonant \quotes{{\padauktext မ}} (Ma) for Mandalay city) and phrase level signs. Based on the previous studies relating to effectiveness of Myanmar word segmentation schemes for SMT \cite{Ye_ICCA2013}, we also decided to use syllable segmentation for MSL. We used Regular Expression (RE) based Myanmar syllable segmentation tool named "sylbreak" \cite{sylBreak}.

%In SMT, word segmentation is a necessary step in order to yield a set of tokens upon which the alignment and indeed the whole machine learning process can operate. We did sign unit based word segmentation for both text representation of MSL and MSW.
    
\section{Experimental Methodology}
\label{sec:experimentalMethodology}

\subsection{Phrase-based Statistical Machine Translation (PBSMT)}
A PBSMT translation model is based on phrasal units \cite{Kohen_NAACL_2003}, \cite{Och_2003}. Here, a phrase is simply a contiguous sequence of words and generally, not a linguistically motivated phrase. A phrase-based translation model typically gives better translation performance than word-based models. We can describe a simple phrase-based translation model consisting of phrase-pair probabilities extracted from corpus and a basic reordering model, and an algorithm to extract the phrases to build a phrase-table \cite{Specia_2011}.

\subsection{Hierarchical Phrase-based Statistical Machine Translation (HPBSMT)}
The hierarchical phrase-based SMT approach is a model \cite{Chiang_HPBSMT_2007} based on synchronous context-free grammar. The model is able to be learned from a corpus of unannotated parallel text. The advantage this technique offers over the phrase-based approach is that the hierarchical structure is able to represent the word re-ordering process. The re-ordering is presented explicitly rather than encoded into a lexicalized re-ordering model (commonly used in purely phrase-based approaches). This makes the approach particularly applicable to language pairs that require long-distance re-ordering during the translation process \cite{Braune_2012}.

\subsection{Operation Sequence Model (OSM)}
The Operation Sequence Model (OSM) \cite{Durrani_2011}, combines the benefits of phrase-based and N-gram-based SMT \cite{Mariὸo_NgramMT_2006} and remedies their drawbacks. It is based on minimal translation units, capture source and target context across phrasal boundaries and simultaneously generate source and target units. Providing a strong coupling of lexical generation and reordering gives a better reordering mechanism than PBSMT. The list of operations can be divided into two groups and they are five translation operations (Generate (X, Y), Continue Source Cept, Generate Identical, Generate Source Only (X) and Generate Target Only (Y)) and three reordering operations (Insert Gap, Jump Back (N) and JumpForward).

\section{EXPERIMENTS}
\label{sec:experiments}

\subsection{Corpus Statistics}
\label{subsec:corpusStatistics}

We used 1,448 Myanmar sign language and Myanmar SignWriting parallel sentences, which is a collection of general domain (refer Section~\ref{sec:corpusPreparation}). In this experiment, 1,000 sentences were used for training, 170 sentences for development and 278 sentences for evaluation.

%It contains sign text transcribed with Myanmar language, phrases and sentences for emergency situation such as fires, earthquake, floods, storms, accidents, police and health. 

\subsection{Moses SMT System}
\label{moses}

We used the PBSMT, HPBSMT and OSM provided by the Moses toolkit \cite{Kohen_moses_2009} for training the PBSMT, HPBSMT and OSM statistical machine translation systems. The word segmented source language was aligned with the word segmented target languages using GIZA++ \cite{Och_alignment_}. The alignment was symmetrized by grow-diag-final-and heuristic \cite{Koehn_2003}. The lexicalized recording model was trained with the msd-bidirectional-fe option \cite{Tillmann_2004}. We use KenLM for training the 5-gram language model with interpolated modified Kneser-Ney discounting \cite{Heafield_KenLM_2011}, \cite{Chen_1996}. Minimum error rate training (MERT) \cite{Och_MERT_2003} was used to tune the decoder parameters and the decoding was done using the Moses decoder (version 2.1.1) \cite{Kohen_moses_2009}. We used default settings of Moses for all experiments. Our current parallel corpus size is limited and thus 10-fold cross validation was done for all experiments. 

\subsection{Evaluation}
\label{evaluation}

We used two automatic criteria for the evaluation of the machine translation output. One was the de facto standard automatic evaluation metric Bilingual Evaluation Understudy (BLEU) \cite{Papineni_BLEU_2001} and the other was the Rank-based Intuitive Bilingual Evaluation Measure (RIBES) \cite{Isozaki_RIBES}. The BLEU score measures the adequacy of the translations and RIBES is suitable for distance language pairs such as Myanmar and English. The higher BLEU and RIBES scores are better.

\section{Result and Discussion}
\label{resultAndDiscussion}

The BLEU and RIBES score results for machine translation experiments with PBSMT, HPBSMT and OSM between MSL (word) and MSW (word) are shown in Table~\ref{tab:result_sl_WORD_to_sw}. The results for MSL (syllable) and MSW (word) pair are shown in Table~\ref{tab:result_sl_SYL_to_sw}. RIBES scores are shown in brackets. Bold numbers indicate the highest scores among the three SMT approaches.

%TABLE I.  bleu  and Ribes scores of word-sw Segmentation pair for PBSMT, HPBSMT and OSM
\begin{table}[htbp]
\caption{BLEU and RIBES scores of sign language (word) and SignWriting pair for PBSMT, HPBSMT and OSM}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{src-trg}&\multicolumn{3}{|c|}{\textbf{Word Segmented MSL}}\\
\cline{2-4} 
\textbf{} & \textbf{\textit{PBSMT}}& \textbf{\textit{HPBSMT}}& \textbf{\textit{OSM}}\\
\hline
MSL-MSW & \shortstack{34.44 \\ (0.8014)} & \shortstack{ 34.99 \\ (0.8049)} & \textbf{\shortstack{37.54  \\ (0.8280)}}\\
\hline
MSW-MSL & \shortstack{52.66 \\ (0.8754)} & \textbf{\shortstack{52.79 \\ (0.8756)}} & \shortstack{49.99  \\ (0.8675)}\\
\hline
\multicolumn{4}{l}{*the values inside the parentheses are RIBES scores}
\end{tabular}
\label{tab:result_sl_WORD_to_sw}
\end{center}
\end{table}


%TABLE II.  bleu  and Ribes scores of syllable-sw Segmentation pair for PBSMT, HPBSMT and OSM
\begin{table}[htbp]
\caption{BLEU and RIBES scores of sign language (syllable) and SignWriting pair for PBSMT, HPBSMT and OSM}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{src-trg}&\multicolumn{3}{|c|}{\textbf{Syllable Segmented MSL}}\\
\cline{2-4} 
\textbf{} & \textbf{\textit{PBSMT}}& \textbf{\textit{HPBSMT}}& \textbf{\textit{OSM}}\\
\hline
MSL-MSW & \shortstack{33.99 \\ (0.8206)} & \shortstack{34.04 \\ \textbf{(0.8260)}} & \shortstack{\textbf{34.38} \\ (0.8200)}\\
\hline
MSW-MSL & \shortstack{49.47 \\ (0.8660)} & \shortstack{49.62 \\ (0.8650)} & \shortstack{\textbf{50.42}  \\ \textbf{(0.8676)}}\\
\hline
\multicolumn{4}{l}{*the values inside the parentheses are RIBES scores}
\end{tabular}
\label{tab:result_sl_SYL_to_sw}
\end{center}
\end{table}

Looking at the results in Table~\ref{tab:result_sl_WORD_to_sw} and ~\ref{tab:result_sl_SYL_to_sw}, MSL(word)-MSW segmentation scheme of MSL was by far the most effective for both MSL-MSW and MSW-MSL translations. In Table.~\ref{tab:result_sl_WORD_to_sw}, MSL-MSW translation achieved the highest BLEU and RIBES scores (37.54 and 0.8280) using OSM approach and MSW-MSL translation gave the highest BLEU and RIBES scores (52.79 and 0.8756) in HPBSMT. From the overall results, it can be clearly seen that OSM approach is better for both MSL to MSW and MSW to MSL translations. PBSMT and HPBSMT results are comparable for both word and syllable segmentations. If we only focus on syllable segmentation experiments (see Table.~\ref{tab:result_sl_SYL_to_sw}), all three SMT approaches, PBSMT, HPBSMT and OSM results are comparable. 

\section{Error Analysis}
\label{sec:errorAnalysis}

We analyzed the translated outputs using Word Error Rate (WER) \cite{WER_wiki}. We used the SCLITE (score speech recognition system output) program from the NIST scoring toolkit SCTK version 2.4.10 for making dynamic programming based alignments between reference (ref) and hypothesis (hyp) and calculation of WER. The formula for WER can be stated as equation (\ref{eq_WER}):

\begin{equation}
\label{eq_WER}
WER=\frac{(N_i + N_d + N_s) \times 100}{ N_d + N_s + N_c}
\end{equation}

where $N_i$ is the number of insertions, $N_d$ is the number of deletions, $N_s$ is the number of substitutions, $N_c$ is the number of correct words. Note that if the number of insertions is very high, the WER can be greater than 100\%. The following example shows WER calculation on the translated outputs of three SMT approaches for MSL-MSW language pair with the word segmentation method. In this example, S=1, D=1, I=1, C=4, N=6 for PBSMT and OSM, its WER is equal to 50\%, S=2, D=1, I=1 for HPBSMT and its WER is equal to 66.67 \%. \\

%whole sentence of OSM is equal to 83.33\%.

                       
% WER= (S+D+I)/ N = (S+D+I) / (S+D+C) 	(1)

%Where S is the number of substitutions, D is the number of deletions, I is the number of insertions, C is the number of correct words and N is the number of words in the reference (N = S+D+C) \cite{WER_wiki}. 

\begin{figure}[htbp]
\centerline{\includegraphics[width=0.5\textwidth]{./fig/example-sw-wer-edited.pdf}}
\caption{An example of reference and hypothesis of PBSMT, HPBSMT and OSM}
\label{fig:ref_hyp}
\end{figure}

\noindent
The followings are the annotation of above MSW sentences into MSL for the readers (the underlined words are pointing the differences with the reference): \\ \\
\noindent 
Ref:		{\padauktext မီးသတ် ကား အရေးပေါ် အခု လာမယ် ။} \\
PBSMT Hyp:	{\padauktext ကား အရေးပေါ် အခု \underline{လွှတ်} \underline{ရ} ။} \\
HPBSMT Hyp:	{\padauktext ကား အရေးပေါ် \underline{လွှတ်} \underline{ရ} \underline{အခု} ။} \\
OSM Hyp:	{\padauktext ကား အရေးပေါ် အခု \underline{လွှတ်} \underline{ရ} ။} \\

Fig. \ref{fig:sl2sw} and Fig. \ref{fig:sw2sl} present the WER percentages of translation between MSL and MSW. The results show that \quotes{word segmented} MSL gave the lower WER values for both MSL to MSW and MSW to MSL translations. 

%Fig. 5. WER of Myanmar Sign Language to Myanmar SignWriting using PBSMT, HPBSMT and OSM

\begin{figure}[htbp]
%\begin{figure*}[t!]
%\centerline{\includegraphics[width=\textwidth]{./fig/signmaker_editor.pdf}}
\centerline{\includegraphics[width=0.5\textwidth]{./graph/sl2msw-graph.pdf}}
\caption{WER of machine translation from Myanmar sign language to Myanmar SignWriting}
\label{fig:sl2sw}
\end{figure}

%Fig. 6. WER of Myanmar SignWriting to Myanmar Sign Language using PBSMT, HPBSMT and OSM

\begin{figure}[htbp]
%\begin{figure*}[t!]
%\centerline{\includegraphics[width=\textwidth]{./fig/signmaker_editor.pdf}}
\centerline{\includegraphics[width=0.5\textwidth]{./graph/sl2msw-graph.pdf}}
\caption{WER of machine translation from Myanmar SignWriting to Myanmar sign language}
\label{fig:sw2sl}
\end{figure}

%Fig 4 and Fig 5 present the WER percentages of translation between Myanmar sign language and Myanmar SignWriting. The results show that word-SW segmentation pairs gave the lowest WER values.


\begin{table*}[h!]
  \centering
  \begin{tabular}{ | m{3cm} | m{3cm} | m{6.5cm} | }
    \hline
    Reference & Hypothesis & Ref-Hyp Description in Myanmar Language\\ \hline
%    \shortstack{
%{\padauktext {\Large မလုပ်နဲ့}}\\ {\padauktext {\Large ရထား}}\\{\padauktext {\Large ဆရာဝန်}}\\{\padauktext %{\Large မသုံးနဲ့}}\\{\padauktext {\Large မလုပ်နဲ့}}\\{\padauktext {\Large ဆေးစစ်}}\\{\padauktext {\Large လျှပ်စစ်}}\\{\padauktext {\Large ခံလိုက်ရပြီ}}\\{\padauktext {\Large အလုပ်}}\\{\padauktext {\Large ရေ}}}
   \begin{minipage}{.3\textwidth}
      \includegraphics[width=0.46\linewidth]{./confusion-pair/ref-pbsmt-confusionpair-cropped.pdf}
    \end{minipage} 
    &
    \begin{minipage}{.3\textwidth}
      \includegraphics[width=0.42\linewidth]{./confusion-pair/hyp-pbsmt-confusionpair-cropped.pdf}
    \end{minipage}    
    &
   \begin{minipage}{.3\textwidth}
      \includegraphics[width=1.15\linewidth]{./confusion-pair/conf-pair-my2-cropped.pdf}
    \end{minipage}   
    \\ \hline
  \end{tabular}
  \caption{Top 10 confusion pairs of PBSMT model}\label{table:confusionPair}
\end{table*}

%Frequency
%\shortstack{\\7\\4\\4\\3\\3\\3\\3\\3\\3\\3}

From our detail analysis on confusion pairs of three SMT approaches, most of the confusion pairs are caused by the three main reasons and they are (1) the nature of the sign language (2) some errors in the reference or human mistakes (3) limited size of the training data. For example, the top 10 confusion pairs of PBSMT translation model is shown in Table.~\ref{table:confusionPair}. In this table, the 1\textsuperscript{st} column is the reference, the 2\textsuperscript{nd} column is the hypothesis (i.e. output of the PBSMT translation model) and the 3\textsuperscript{rd} column is the description of reference and hypothesis in Myanmar written text. Here, confusion pair number 1, 4 and 5 are caused by the same sign language usage for the several meanings. In Myanmar sign language, the word {\padauktext မဟုတ်} (\quotes{No} in English), the phrase {\padauktext မလုပ်နဲ့} (\quotes{Don't do it!} in English), the word {\padauktext မဖြစ်} (\quotes{do not} in English) and the phrase {\padauktext မသုံးနဲ့} (\quotes{Don't use it!} in English) are the same. And thus, the translation model couldn't learn well and we assumed this is also relating to the limited size of our training data. The confusion pair number 2 is caused by the error of the reference data. The confusion pair number 3 and 10 are caused by the sign language dialects (i.e. the difference between Yangon and Mandalay cities sign langauges). One more good example of the confusion pair caused by the sign language nature is the number 7 confusion pair (see Table.~\ref{table:confusionPair}). Although one hand sign is using in the reference of the confusion pair number 7, the hypothesis is using two hands.
    
\section{Conclusion}
\label{sec:conclusion}

This paper has presented the first study of the statistical machine translation between Myanmar sign language and Myanmar SignWriting. We implemented three SMT systems (PBSMT, HPBSMT and OSM) with our developing MSL-MSW parallel corpus. We also investigated the effectiveness of two word segmentation schemes (word segmentation and syllable segmentation for Myanmar sign language) for SMT. Our results clearly show that OSM approach achieved the highest translation performance for MSL to MSW translation. However, the HPBSMT approach achieved the highest translation performance for MSW to MSL translation. From our investigation on the effectiveness of word segmentations for MSL-MSW machine translations, the results proved that word segmentation is better than syllable segmentation for MSL side. 

In the future work, we plan to expand the MSL-MSW parallel data and conduct experiments on SMT with SignWriting character level (i.e combination of basic symbol, filling symbol and spatial rotation symbol as a one SignWriting character) segmentation approach. We are also doing experiments on Myanmar written text to MSW machine translations.

%Our results clearly show that HPBSMT and OSM with syllable segmentation for both source and target languages achieved the highest BLEU and RIBES scores for translation between MSL and MSW. 

\section*{Acknowledgment}

We would like to thank principals, teachers, SL trainers and students of School for the Deaf (Mandalay), Mary Chapman Chapman School for the Deaf Children (Yangon) and School for the Deaf, Tarmwe (Yangon), Myanmar Deaf Society and Literacy and Language Development for the Deaf for their kind contribution to our research. This research is partially supported by Ministry of Education, Department of Higher Education (Myanmar).

%%%%%%%%%%%%%%%%%%%%%%%%



%``Fig.~\ref{fig}'', even at the beginning of a sentence.





\begin{thebibliography}{00}

%\bibitem{b1} G. Eason, B. Noble, and I. N. Sneddon, ``On certain integrals of Lipschitz-Hankel type involving products of Bessel functions,'' Phil. Trans. Roy. Soc. London, vol. A247, pp. 529--551, April 1955.
%\bibitem{b2} J. Clerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol. 2. Oxford: Clarendon, 1892, pp.68--73.
%\bibitem{b3} I. S. Jacobs and C. P. Bean, ``Fine particles, thin films and exchange anisotropy,'' in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New York: Academic, 1963, pp. 271--350.
%\bibitem{b4} K. Elissa, ``Title of paper if known,'' unpublished.
%\bibitem{b5} R. Nicole, ``Title of paper with only first word capitalized,'' J. Name Stand. Abbrev., in press.
%\bibitem{b6} Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, ``Electron spectroscopy studies on magneto-optical media and plastic substrate interface,'' IEEE Transl. J. Magn. Japan, vol. 2, pp. 740--741, August 1987 [Digests 9th Annual Conf. Magnetics Japan, p. 301, 1982].
%\bibitem{b7} M. Young, The Technical Writer's Handbook. Mill Valley, CA: University Science, 1989.

%%%%%%%%%%%

\bibitem{census_2014} The population and housing census of Myanmar, 2014
\bibitem{Hutchins_2000} Hutchins, W. J., "Early years in machine translation", John Benjamins Publishing, 2000, USA doi: 10.1075/sihols.97
\bibitem{Hutchins_1992} Hutchins, W. J., and Somers, H. L., "An introduction to machine translation", Academic Press, 1992, London, ISBN-13: 978-0123628305
\bibitem{Nirenburg_2004} Nirenburg, S., and Raskin, V., "Ontological semantics", The MIT Press, 2004 ISBN: 9780262140867
\bibitem{Bangham_2000} Bangham, J. A., and Cox, S. J., "Signing for the deaf using virtual humans", In Proceeding of the Speech and Language Processing for Disabled and Elderly People (Ref. No. 2000/025), IEE Seminar, 2000, London, UK
\bibitem{Angus_1999} Angus B., and Smith, G., "English to American sign language machine translation of weather reports", In Proceeding of the 2nd high desert student conference in linguistics (HDSL2), 1999, Albuquerque, New Mexico, pp. 23–30
\bibitem{Zijl_2003} Zijl, L. V., and Barker, D., "South African sign language machine translation system", In Proceeding of the 2nd international conference on computer graphics, virtual reality, visualisation and interaction in Africa (ACM SIGGRAPH), 2003, Cape Town, South Africa, pp. 49–52
\bibitem{Morrissey_2006} Morrissey, S. and Way, A., "Experiments in sign language machine translation using examples", In Proceeding of the IBM CASCON 2006 Dublin symposium, Dublin, Ireland.
\bibitem{Stein_2006} Stein, D., Bungeroth, J., and Ney, H., "Morpho-syntax based statistical methods for sign language translation", In  Proceeding of the 11th annual conference of the European association for machine translation, June, 2006, Oslo, Norway.
\bibitem{Almasoud_2012} Almasoud, Al-Khalifa., "Semantic system for Arabic Text-to-SignWriting Translation", Journal of Software Engineering and Applications, 2012,5,604-612
\bibitem{Thompson_2006} Thompson, RobYin; Emmorey, Karen; Kluender, Robert, "The Relationship between Eye Gaze and Verb Agreement in American Sign Language: An Eye-tracking Study". Natural Language and Linguistic Theory. 24 (2), 2006, pp. 571–604 doi:10.1007/s11049-005-1829-y. 
\bibitem{Baker1980} Baker, Charlotte, and Dennis Cokely, "American Sign Language: A teacher's resource text on grammar and culture", 1980, Silver Spring, MD: T.J. Publishers. 
\bibitem{Sutton_1998} Sutton-Spence, Rachel, and Bencie Woll, "The linguistics of British Sign Language", Cambridge: Cambridge University Press, 1998
\bibitem{MSL_conversation_2009} "Myanmar Sign Language Basic Conversation Book", Ministry of Social Welfare, Relief and Resettlement, Department of Social Welfare, Japan International Cooperation Agency, 1st Edition, August 2009, Daw Yu Yu Swe, Department of Social Welfare
\bibitem{SW_hp} SignWriting Site: http://www.signwriting.org/read.html
\bibitem{SW_manual_2010} Valerie Sutton and Adam Frost., "SignWriting Hand Symbols in ISWA2010: Manual 2"
\bibitem{SW_unicode} Sutton SignWriting Unicode., \\ http://www.unicode.org/charts/PDF/U1D800.pdf 
\bibitem{Ye_PACLIN_2015} Ye Kyaw Thu, Vichet Chea, Andrew Finch, Masao Utiyama and Eiichiro Sumita, "A Large-scale Study of Statistical Machine Translation Methods for Khmer Language", 29th Pacific Asia Conference on Language, Information and Computation, October 30 - November 1, 2015, Shanghai, China, pp. 259-269
\bibitem{Kohen_NAACL_2003} Kohen, P., Och, F .J., Marcu, D., "Statistsical phrase-based translation, In HLT-NAACL, 2003, url: http://acl.ldc.upenn.edu/N/N03/N03-1017.pdf
\bibitem{Och_2003} Och, F .j., Marcu, D., Statistical phrase-based translation, 2003, p.127-133.
\bibitem{Specia_2011} Specia, L.. Tutorial, fundamental and new approaches to statistical machine translation. In: International Conference Recent Advances in Natural Language Processing, 2011
\bibitem{Chiang_HPBSMT_2007} Chiang, D.. Hierarchical phrase-based translation. Comput Linguist 2007;33(2):201-228. url: http://dx.doi.org/10.1162/coli.2007.33.2.201. doi:10.1162/coli.2007.33.2.201.
\bibitem{Braune_2012} Braune, F., Gojun, A., Fraser, A.. Long-distance reordering during search for hierarchical phrase-based smt. In: EAMT 2012: Proceedings of the 16th Annual Conference of the European Association for Machine Translation, Trento, Italy, Citeseer; 2012, pp. 177-184
\bibitem{Durrani_2011} Durrani, N. Schmid, H., Fraser, A.M., A joint sequence translation model with integrated reordering. In: Lin, D., Matsumoto, Y., Mihalcea, R., editors. ACL. The Association for Computer Linguistics. ISBN 978-1-932432-87-9;2011, pp. 1045-1054 url: http://dblp.uni-trier.de/db/conf/acl/acl2011.html\#DurraniSF11
\bibitem{Mariὸo_NgramMT_2006} Mariὸo, J.B., Banchs, R.E., Crego, J.M., de Gispert, A., Lambert, P., Fonollosa, J.A.R., et al, N-gram-based machine translation, Comput Linguist 2006;32(4):527-549. url: http://dx.doi.org/10.1162/coli.2006.32.4.527. Doi:10.1162/coli.2006.32.4.527.
\bibitem{Kohen_moses_2009} Philipp Koehn and Barry Haddow. 2009. Edinburgh’s Submission to all Tracks of the WMT2009 Shared Task with Reordering and Speed Improvements to Moses. In Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 160–164. 
\bibitem{Och_alignment_} Och, F.J., Ney, H.. "Improved statistical alignment model", In ACL00. Hong Kong, China, 2000, pp. 440-447
\bibitem{Koehn_2003} Koehn, P., Och, F.J.., Marcu, D.., "Statistical phrase-based translation", In Proceedings of the Human Language Technology Conference, 2003, Edmonton, Canada, pp. 48-54
\bibitem{Tillmann_2004} Tillmann, C.., "A unigram orientation model for statistical machine translation", In Proceedings of HLT-NAACL 2004: Short Papers; HLT-NAACL-Short’04. Stroudsburg, PA, USA: Association for Computational Linguistics. ISBN 1-932432-24-8; 2004, pp.101-104, http://d1.acm.org/citation.cfm?id-1613984.1614010.
\bibitem{Heafield_KenLM_2011} Heafield, Kenneth, "KenLM: Faster and Smaller Language Model Queries", Proceedings of the Sixth Workshop on Statistical Machine Translation; WMT '11, 2011, Association for Computational Linguistics, Edinburgh, Scotland, pp. 187-197 ISBN- 978-1-937284-12-1
\bibitem{Chen_1996} Chen, S.F., Goodman, J., "An empirical study of smoothing techniques for language modeling", In Proceedings of the 34th annual meeting on Association for Computational Linguistics. Association for Computational Linguistics; 1996, pp. 310-318.
\bibitem{Och_MERT_2003} Och, F.J., "Minimum error rate training for statistical machine translation", In Proceedings of the 41st Meeting of the Association for Computational Linguistics (ACL 2003). Sapporo, Japan
\bibitem{Papineni_BLEU_2001} Papineni, K., Roukos, S., Ward, T., Zhu, W., "Bleu: a Method for Automatic Evaluation of Machine Translation". IBM Research Report rc22176 (w0109022), 2001, Thomas J. Watson Research Center, In ACL '02 Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, July 07 - 12, 2002, Philadelphia, Pennsylvania, pp. 311-318
\bibitem{Isozaki_RIBES} Isozaki, H., Hirao, T., Duh, K., Sudoh, K., Tsukada, H., "Automatic evaluation of translation quality for distant language pairs", In Proceedings of the Conference on Empirical Methods in Natural Language Processing. pp. 944–952.
%\bibitem{} EMNLP ’10, Association for Computational Linguistics, 2010, Stroudsburg, PA, USA http://dl.acm.org/citation.cfm?id=1870658.1870750
\bibitem{WER_wiki} Wikipedia of Word Error Rate: https://en.wikipedia.org/wiki/Word\_error\_rate
\bibitem{Ye_ICCA2013} Ye Kyaw Thu, Andrew Finch, Yoshinori Sagisaka and Eiichiro Sumita, "A Study of Myanmar Word Segmentation Schemes for Statistical Machine Translation", In Proceedings of the 11th International Conference on Computer Applications (ICCA 2013), February 26-27, 2013, Yangon, Myanmar, pp. 167-179
\bibitem{sylBreak} https://github.com/ye-kyaw-thu/sylbreak
\end{thebibliography}

\end{document}
