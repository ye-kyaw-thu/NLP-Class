{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgqeD3n4ge_3",
        "outputId": "ecfa725c-c5fa-4c90-c1d6-96a9331e15b4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVQVc1vP20HX"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxTNRVJge0OU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFLL5aA64AJD"
      },
      "source": [
        "lines = pd.DataFrame(columns=['source','target','file_name'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLivn25seWQg"
      },
      "source": [
        "\n",
        "tag = []\n",
        "word = []\n",
        "with open('drive/MyDrive/pos-parallel-underandequal-len150') as tag_file:\n",
        "    for sen in tag_file:\n",
        "        \"\"\"if(len(sen)>200):\n",
        "            continue\n",
        "        #ဗိုလ်ချုပ်/n|အောင်ဆန်း/n => ဗိုလ်ချုပ်/n အောင်ဆန်း/n\n",
        "        sen = sen.strip().replace('|',' ')\n",
        "        word.append(' '.join([i[:i.find('/')] for i in sen.split()]))\n",
        "        tag.append(' '.join([i[i.find('/')+1:] for i in sen.split()]))\n",
        "        \"\"\"\n",
        "        w,t = sen.split('<|||>')\n",
        "        word.append(w.strip())\n",
        "        tag.append(t.strip())\n",
        "lines['source'] = word\n",
        "lines['target'] = tag\n",
        "lines.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "KGkBaFcre0OX",
        "outputId": "6af2d24b-b67c-460a-d091-c261d6573c7b"
      },
      "source": [
        "with open('drive/MyDrive/pos-train') as train_file:\n",
        "    for sen in train_file:\n",
        "        sen = sen.strip()\n",
        "        w,t = sen.split('<|||>')\n",
        "        lines = lines.append({'source':w,'target':t,'file_name':'train'},ignore_index=True)\n",
        "\n",
        "with open('drive/MyDrive/pos-dev') as dev_file:\n",
        "    for sen in dev_file:\n",
        "        sen = sen.strip()\n",
        "        w,t = sen.split('<|||>')\n",
        "        lines = lines.append({'source':w,'target':t,'file_name':'dev'},ignore_index=True)\n",
        "\n",
        "with open('drive/MyDrive/pos-test') as test_file:\n",
        "    for sen in test_file:\n",
        "        sen = sen.strip()\n",
        "        w,t = sen.split('<|||>')\n",
        "        lines = lines.append({'source':w,'target':t,'file_name':'test'},ignore_index=True)\n",
        "print(lines.shape)\n",
        "lines.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10997, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>file_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>အောင်ဆန်း ၏ မိခင် မျိုးရိုး ထဲ တွင် ရာထူး ကြီး...</td>\n",
              "      <td>n ppm n n ppm ppm n adj n adj v part part ppm ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>လူသား ချင်း စာနာ မှု အတွက် ဗိသုကာ ပုံစံ သည် ရေ...</td>\n",
              "      <td>n part v part ppm n n ppm adv v v part n part ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ထို ရာသီ ကား အဿဝဏီ နက္ခတ် နှင့် ယှဉ် ၍ လပြည့် ...</td>\n",
              "      <td>adj n part n n ppm v conj n conj n part v ppm ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>၁၂ ၊ မေ ၊ ၁၇၈၃ တွင် နန်း သိမ်း ပွဲ ဖြင့် စတင် ...</td>\n",
              "      <td>num punc n punc num ppm n v n ppm v v ppm punc</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>စူဇူကီး သည် ဗိုလ် မိုးကြိုး ဖြစ် လာ ပြီး ၊ အော...</td>\n",
              "      <td>n ppm n n v part conj punc n ppm n n v part pp...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              source  ... file_name\n",
              "0  အောင်ဆန်း ၏ မိခင် မျိုးရိုး ထဲ တွင် ရာထူး ကြီး...  ...     train\n",
              "1  လူသား ချင်း စာနာ မှု အတွက် ဗိသုကာ ပုံစံ သည် ရေ...  ...     train\n",
              "2  ထို ရာသီ ကား အဿဝဏီ နက္ခတ် နှင့် ယှဉ် ၍ လပြည့် ...  ...     train\n",
              "3  ၁၂ ၊ မေ ၊ ၁၇၈၃ တွင် နန်း သိမ်း ပွဲ ဖြင့် စတင် ...  ...     train\n",
              "4  စူဇူကီး သည် ဗိုလ် မိုးကြိုး ဖြစ် လာ ပြီး ၊ အော...  ...     train\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "71xOYj2g3KPv",
        "outputId": "7980e82e-5d76-4fc0-823b-498de9645c18"
      },
      "source": [
        "dic = {}\n",
        "for line in lines.target:\n",
        "  for word in line.split():\n",
        "    if word in dic:\n",
        "      dic[word] += 1\n",
        "    else:\n",
        "      dic[word] = 1\n",
        "df = pd.DataFrame(list(dic.items()),columns = ['tag','count'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tag</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>n</td>\n",
              "      <td>65007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ppm</td>\n",
              "      <td>38654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>adj</td>\n",
              "      <td>7181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v</td>\n",
              "      <td>33469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>part</td>\n",
              "      <td>52219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>punc</td>\n",
              "      <td>15713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>adv</td>\n",
              "      <td>2869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>conj</td>\n",
              "      <td>11624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>num</td>\n",
              "      <td>3940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>pron</td>\n",
              "      <td>2679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>abb</td>\n",
              "      <td>311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>tn</td>\n",
              "      <td>2349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>fw</td>\n",
              "      <td>2296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>int</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>sb</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     tag  count\n",
              "0      n  65007\n",
              "1    ppm  38654\n",
              "2    adj   7181\n",
              "3      v  33469\n",
              "4   part  52219\n",
              "5   punc  15713\n",
              "6    adv   2869\n",
              "7   conj  11624\n",
              "8    num   3940\n",
              "9   pron   2679\n",
              "10   abb    311\n",
              "11    tn   2349\n",
              "12    fw   2296\n",
              "13   int     98\n",
              "14    sb    200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qI6tHNC-Nrr",
        "outputId": "c3bcfd3c-d2b8-4e46-b1ef-5554c7893e57"
      },
      "source": [
        "dic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'abb': 311,\n",
              " 'adj': 7181,\n",
              " 'adv': 2869,\n",
              " 'conj': 11624,\n",
              " 'fw': 2296,\n",
              " 'int': 98,\n",
              " 'n': 65007,\n",
              " 'num': 3940,\n",
              " 'part': 52219,\n",
              " 'ppm': 38654,\n",
              " 'pron': 2679,\n",
              " 'punc': 15713,\n",
              " 'sb': 200,\n",
              " 'tn': 2349,\n",
              " 'v': 33469}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "i0eBS53a4B1n",
        "outputId": "43a9e67c-dcb9-4f6c-bc73-dde78febb6d3"
      },
      "source": [
        "sns.barplot(x='count',y='tag',data = df,order = sorted(dic,key=dic.__getitem__,reverse=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f00405af6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "bsLiANHJXdrh",
        "outputId": "f6a8f191-2587-4f8b-eccd-c8fa90fbf7b8"
      },
      "source": [
        "lines.groupby('file_name').count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>file_name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>dev</th>\n",
              "      <td>1099</td>\n",
              "      <td>1099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>1099</td>\n",
              "      <td>1099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>8799</td>\n",
              "      <td>8799</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           source  target\n",
              "file_name                \n",
              "dev          1099    1099\n",
              "test         1099    1099\n",
              "train        8799    8799"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "T6F3pGCT7P8A",
        "outputId": "de0183fc-4739-4a5b-a3d0-eabe460d3917"
      },
      "source": [
        "lines['target'] = lines['target'].apply(lambda x: 'start_ '+x+' _end')\n",
        "lines['source_len'] = lines['source'].apply(lambda x: len(x.split()))\n",
        "lines['target_len'] = lines['target'].apply(lambda x: len(x.split()))\n",
        "lines.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>file_name</th>\n",
              "      <th>source_len</th>\n",
              "      <th>target_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>အောင်ဆန်း ၏ မိခင် မျိုးရိုး ထဲ တွင် ရာထူး ကြီး...</td>\n",
              "      <td>start_ n ppm n n ppm ppm n adj n adj v part pa...</td>\n",
              "      <td>train</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>လူသား ချင်း စာနာ မှု အတွက် ဗိသုကာ ပုံစံ သည် ရေ...</td>\n",
              "      <td>start_ n part v part ppm n n ppm adv v v part ...</td>\n",
              "      <td>train</td>\n",
              "      <td>35</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ထို ရာသီ ကား အဿဝဏီ နက္ခတ် နှင့် ယှဉ် ၍ လပြည့် ...</td>\n",
              "      <td>start_ adj n part n n ppm v conj n conj n part...</td>\n",
              "      <td>train</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>၁၂ ၊ မေ ၊ ၁၇၈၃ တွင် နန်း သိမ်း ပွဲ ဖြင့် စတင် ...</td>\n",
              "      <td>start_ num punc n punc num ppm n v n ppm v v p...</td>\n",
              "      <td>train</td>\n",
              "      <td>14</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>စူဇူကီး သည် ဗိုလ် မိုးကြိုး ဖြစ် လာ ပြီး ၊ အော...</td>\n",
              "      <td>start_ n ppm n n v part conj punc n ppm n n v ...</td>\n",
              "      <td>train</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              source  ... target_len\n",
              "0  အောင်ဆန်း ၏ မိခင် မျိုးရိုး ထဲ တွင် ရာထူး ကြီး...  ...         17\n",
              "1  လူသား ချင်း စာနာ မှု အတွက် ဗိသုကာ ပုံစံ သည် ရေ...  ...         37\n",
              "2  ထို ရာသီ ကား အဿဝဏီ နက္ခတ် နှင့် ယှဉ် ၍ လပြည့် ...  ...         17\n",
              "3  ၁၂ ၊ မေ ၊ ၁၇၈၃ တွင် နန်း သိမ်း ပွဲ ဖြင့် စတင် ...  ...         16\n",
              "4  စူဇူကီး သည် ဗိုလ် မိုးကြိုး ဖြစ် လာ ပြီး ၊ အော...  ...         18\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWdN8zOge0Oa"
      },
      "source": [
        "arr = []\n",
        "with open('/home/acyclic/NLP/MTRSS/pbsmt/data/train.my') as my:\n",
        "    for line in my:\n",
        "        arr.append(line.replace('။','').strip())\n",
        "lines['source'] = arr\n",
        "arr =[]\n",
        "with open('/home/acyclic/NLP/MTRSS/pbsmt/data/train.rk') as rk:\n",
        "    for line in rk:\n",
        "        arr.append(line.replace('။','').strip())\n",
        "lines['target'] = arr\n",
        "lines.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT78fV3pe0Ob"
      },
      "source": [
        "lines['source'] = lines['source'].apply(lambda x: re.sub(r'[^က-၏]',' ',x))\n",
        "lines['target'] = lines['target'].apply(lambda x: re.sub(r'[^က-၏]',' ',x))\n",
        "lines.head()\n",
        "\n",
        "lines['target'] = lines['target'].apply(lambda x: 'start_ '+x+' _end')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgTsPVKue0Od"
      },
      "source": [
        "# Find all the source and target words and sort them\n",
        "# Vocabulary of Source language\n",
        "all_source_words=set()\n",
        "for source in lines.source:\n",
        "    for word in source.split():\n",
        "        if word not in all_source_words:\n",
        "            all_source_words.add(word)# Vocabulary of Target \n",
        "all_target_words=set()\n",
        "for target in lines.target:\n",
        "    for word in target.split():\n",
        "        if word not in all_target_words:\n",
        "            all_target_words.add(word)\n",
        "# sort all unique source and target words\n",
        "source_words= sorted(list(all_source_words))\n",
        "target_words=sorted(list(all_target_words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PlkKH-HsKzg",
        "outputId": "e1993998-2686-4f0f-ca52-71b0b4083d07"
      },
      "source": [
        "target_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_end',\n",
              " 'abb',\n",
              " 'adj',\n",
              " 'adv',\n",
              " 'conj',\n",
              " 'fw',\n",
              " 'int',\n",
              " 'n',\n",
              " 'num',\n",
              " 'part',\n",
              " 'ppm',\n",
              " 'pron',\n",
              " 'punc',\n",
              " 'sb',\n",
              " 'start_',\n",
              " 'tn',\n",
              " 'v']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AhxhgjBe0Od",
        "outputId": "e6f17474-e92c-485d-87d2-18957b7547fb"
      },
      "source": [
        "#max_source_length= max(lines['source_len'])\n",
        "max_source_length = 150\n",
        "print(\" Max length of the source sentence\",max_source_length)\n",
        "#max_target_length= max(lines['target_len'])\n",
        "max_target_length =150\n",
        "print(\" Max length of the target sentence\",max_target_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Max length of the source sentence 150\n",
            " Max length of the target sentence 150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atB7uxtWe0Of"
      },
      "source": [
        "# creating a word to index(word2idx) for source and target\n",
        "source_word2idx= dict([(word, i+1) for i,word in enumerate(source_words)])\n",
        "target_word2idx=dict([(word, i+1) for i, word in enumerate(target_words)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx5IfLBSe0Oi"
      },
      "source": [
        "#creating a dictionary for index to word for source and target vocabulary\n",
        "source_idx2word= dict([(i, word) for word, i in  source_word2idx.items()])\n",
        "#print(source_idx2word)\n",
        "target_idx2word =dict([(i, word) for word, i in target_word2idx.items()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlT-eAipJ4rz"
      },
      "source": [
        "# Train - Test Split\n",
        "#X, y = lines.source, lines.target\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM8qrEIJe0Om",
        "outputId": "35d1b145-0a42-4731-a6d5-8dbfa5660e3b"
      },
      "source": [
        "\n",
        "X_train = lines.loc[lines['file_name']=='train','source']\n",
        "y_train = lines.loc[lines['file_name']=='train','target']\n",
        "\n",
        "X_dev = lines.loc[lines['file_name']=='dev','source']\n",
        "y_dev = lines.loc[lines['file_name']=='dev','target']\n",
        "\n",
        "X_test = lines.loc[lines['file_name']=='test','source']\n",
        "y_test = lines.loc[lines['file_name']=='test','target']\n",
        "X_train.shape, X_dev.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8799,), (1099,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2Hzcy_PHyis",
        "outputId": "4be35005-a569-4d90-d223-2cb785ab259b"
      },
      "source": [
        "X_dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8799    “ ကုလား တို့ ကျွန် မ ခံ ” ဟူသော စိတ်ထား ရှိ ခဲ...\n",
              "8800     အဲဒါ က လေးဆယ့်ငါး လမ်း မှာ ဟုတ် တယ် မ ဟုတ် လား ။\n",
              "8801    ပုပ်ရဟန်းမင်းကြီး က ဂယ်လီလီယို ကို သူ ၏ ဘဝ အချ...\n",
              "8802                                      ဘေးဖယ် နေ မယ် ။\n",
              "8803    ပထမ မှာ သားရေ ပေါ် တွင် ကပ် ၍ ပေါက် သော အမွေး ...\n",
              "                              ...                        \n",
              "9893    ဤ အမည် မှာ ၁၉၄၈ ခုနှစ် မ တိုင် မီ က ဗြိတိသျှ မ...\n",
              "9894    ပထမ ဒြပ်ပေါင်း တွင် နိုက်ထရိုဂျင် အလေးချိန် ၇ ...\n",
              "9895    အသောက မင်း ကဲ့သို့ ပင် သာသနာ ပြန့်ပွား ထွန်းကာ...\n",
              "9896    ကမ္ဘာ ပေါ် ရှိ ဒေသ များ နှင့် နိုင်ငံ အစုအဝေး ...\n",
              "9897    ခရီးဆောင် အိတ် က အဲဒီ ကို ရောက် မှာ နော် ၊ ဟုတ...\n",
              "Name: source, Length: 1099, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIb6VAZUBhwH",
        "outputId": "d72f95b8-0362-4672-dc13-56d8626ed83c"
      },
      "source": [
        "type(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sszlCkEXe0Om",
        "outputId": "c7933aac-5eaf-4ace-cf33-3a66ca01abad"
      },
      "source": [
        "# Input tokens for encoder\n",
        "num_encoder_tokens=len(source_words)+1\n",
        "# Input tokens for decoder zero padded\n",
        "num_decoder_tokens=len(target_words) +1\n",
        "print(num_encoder_tokens,num_decoder_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15845 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRnM8Zdke0On"
      },
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    ''' Generate a batch of data '''\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_source_length),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_target_length),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_target_length, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                  encoder_input_data[i, t] = source_word2idx[word] \n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_word2idx[word] # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        # Offset by one timestep\n",
        "                        #print(word)\n",
        "                        decoder_target_data[i, t - 1, target_word2idx[word]] = 1.\n",
        "            #print(encoder_input_data.shape,decoder_input_data.shape,decoder_targer_data.shape)\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCpQmSSIe0On"
      },
      "source": [
        "train_samples = len(X_train)\n",
        "val_samples = len(X_dev)\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "latent_dim=500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdq5ekOxe0On"
      },
      "source": [
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utvxwTP6e0Oo",
        "outputId": "a71b4871-5c95-4fe0-b031-210466d3d0e0"
      },
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "print(decoder_outputs.shape)\n",
        "\n",
        "\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "print(decoder_outputs.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, None, 500)\n",
            "(None, None, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_1NMZDSe0Oo"
      },
      "source": [
        "# Define the model that takes encoder and decoder input \n",
        "# to output decoder_outputs\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6PqqcG0e0Op"
      },
      "source": [
        "\n",
        "#tf.keras.utils.plot_model(model, 'my_first_model.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBbDcL3me0Oq"
      },
      "source": [
        "model.compile(optimizer='rmsprop', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRUYKAxLe0Oq"
      },
      "source": [
        "train_samples = len(X_train) # Total Training samples\n",
        "val_samples = len(X_dev)    # Total validation or test samples\n",
        "batch_size = 128\n",
        "epochs = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Hq9CEaNe0Oq",
        "outputId": "9f269dbd-9b68-46c1-97c9-20efbd003c3f"
      },
      "source": [
        "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
        "                    steps_per_epoch = train_samples//batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data = generate_batch(X_dev, y_dev, batch_size = batch_size),\n",
        "                    validation_steps = val_samples//batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "68/68 [==============================] - 18s 151ms/step - loss: 0.3191 - accuracy: 0.3321 - val_loss: 0.2386 - val_accuracy: 0.4726\n",
            "Epoch 2/100\n",
            "68/68 [==============================] - 8s 115ms/step - loss: 0.2239 - accuracy: 0.4772 - val_loss: 0.2254 - val_accuracy: 0.4972\n",
            "Epoch 3/100\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.2099 - accuracy: 0.5089 - val_loss: 0.2108 - val_accuracy: 0.5276\n",
            "Epoch 4/100\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.2007 - accuracy: 0.5290 - val_loss: 0.2033 - val_accuracy: 0.5373\n",
            "Epoch 5/100\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.1935 - accuracy: 0.5499 - val_loss: 0.1952 - val_accuracy: 0.5605\n",
            "Epoch 6/100\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.1853 - accuracy: 0.5713 - val_loss: 0.1900 - val_accuracy: 0.5729\n",
            "Epoch 7/100\n",
            "68/68 [==============================] - 9s 126ms/step - loss: 0.1776 - accuracy: 0.5885 - val_loss: 0.1824 - val_accuracy: 0.5920\n",
            "Epoch 8/100\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.1705 - accuracy: 0.6062 - val_loss: 0.1749 - val_accuracy: 0.6054\n",
            "Epoch 9/100\n",
            "68/68 [==============================] - 9s 126ms/step - loss: 0.1645 - accuracy: 0.6239 - val_loss: 0.1708 - val_accuracy: 0.6181\n",
            "Epoch 10/100\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.1561 - accuracy: 0.6427 - val_loss: 0.1622 - val_accuracy: 0.6382\n",
            "Epoch 11/100\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.1495 - accuracy: 0.6589 - val_loss: 0.1673 - val_accuracy: 0.6245\n",
            "Epoch 12/100\n",
            "68/68 [==============================] - 8s 124ms/step - loss: 0.1435 - accuracy: 0.6717 - val_loss: 0.1536 - val_accuracy: 0.6610\n",
            "Epoch 13/100\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.1352 - accuracy: 0.6898 - val_loss: 0.1515 - val_accuracy: 0.6637\n",
            "Epoch 14/100\n",
            "68/68 [==============================] - 8s 124ms/step - loss: 0.1289 - accuracy: 0.7036 - val_loss: 0.1499 - val_accuracy: 0.6693\n",
            "Epoch 15/100\n",
            "68/68 [==============================] - 9s 126ms/step - loss: 0.1234 - accuracy: 0.7179 - val_loss: 0.1492 - val_accuracy: 0.6740\n",
            "Epoch 16/100\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.1165 - accuracy: 0.7329 - val_loss: 0.1454 - val_accuracy: 0.6830\n",
            "Epoch 17/100\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.1132 - accuracy: 0.7406 - val_loss: 0.1455 - val_accuracy: 0.6806\n",
            "Epoch 18/100\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.1081 - accuracy: 0.7527 - val_loss: 0.1498 - val_accuracy: 0.6823\n",
            "Epoch 19/100\n",
            "68/68 [==============================] - 9s 125ms/step - loss: 0.1031 - accuracy: 0.7637 - val_loss: 0.1408 - val_accuracy: 0.6936\n",
            "Epoch 20/100\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.0977 - accuracy: 0.7762 - val_loss: 0.1385 - val_accuracy: 0.6998\n",
            "Epoch 21/100\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.0913 - accuracy: 0.7904 - val_loss: 0.1421 - val_accuracy: 0.6979\n",
            "Epoch 22/100\n",
            "68/68 [==============================] - 8s 125ms/step - loss: 0.0861 - accuracy: 0.8000 - val_loss: 0.1484 - val_accuracy: 0.6938\n",
            "Epoch 23/100\n",
            "68/68 [==============================] - 8s 125ms/step - loss: 0.0809 - accuracy: 0.8121 - val_loss: 0.1485 - val_accuracy: 0.6972\n",
            "Epoch 24/100\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.0774 - accuracy: 0.8215 - val_loss: 0.1466 - val_accuracy: 0.6981\n",
            "Epoch 25/100\n",
            "68/68 [==============================] - 8s 124ms/step - loss: 0.0727 - accuracy: 0.8316 - val_loss: 0.1505 - val_accuracy: 0.6948\n",
            "Epoch 26/100\n",
            "68/68 [==============================] - 9s 130ms/step - loss: 0.0674 - accuracy: 0.8439 - val_loss: 0.1525 - val_accuracy: 0.6996\n",
            "Epoch 27/100\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.0623 - accuracy: 0.8558 - val_loss: 0.1639 - val_accuracy: 0.6772\n",
            "Epoch 28/100\n",
            "68/68 [==============================] - 9s 126ms/step - loss: 0.0591 - accuracy: 0.8639 - val_loss: 0.1580 - val_accuracy: 0.6991\n",
            "Epoch 29/100\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.0558 - accuracy: 0.8726 - val_loss: 0.1669 - val_accuracy: 0.6968\n",
            "Epoch 30/100\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.0525 - accuracy: 0.8794 - val_loss: 0.1678 - val_accuracy: 0.6995\n",
            "Epoch 31/100\n",
            "68/68 [==============================] - 8s 124ms/step - loss: 0.0485 - accuracy: 0.8897 - val_loss: 0.1707 - val_accuracy: 0.6972\n",
            "Epoch 32/100\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.0454 - accuracy: 0.8975 - val_loss: 0.1831 - val_accuracy: 0.6840\n",
            "Epoch 33/100\n",
            "68/68 [==============================] - 8s 125ms/step - loss: 0.0418 - accuracy: 0.9061 - val_loss: 0.1825 - val_accuracy: 0.6927\n",
            "Epoch 34/100\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.0391 - accuracy: 0.9130 - val_loss: 0.1835 - val_accuracy: 0.6975\n",
            "Epoch 35/100\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.0354 - accuracy: 0.9225 - val_loss: 0.1885 - val_accuracy: 0.6896\n",
            "Epoch 36/100\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.0321 - accuracy: 0.9292 - val_loss: 0.1912 - val_accuracy: 0.6948\n",
            "Epoch 37/100\n",
            "68/68 [==============================] - 8s 124ms/step - loss: 0.0296 - accuracy: 0.9371 - val_loss: 0.1976 - val_accuracy: 0.6922\n",
            "Epoch 38/100\n",
            "68/68 [==============================] - 8s 125ms/step - loss: 0.0274 - accuracy: 0.9425 - val_loss: 0.2046 - val_accuracy: 0.6950\n",
            "Epoch 39/100\n",
            "68/68 [==============================] - 8s 125ms/step - loss: 0.0249 - accuracy: 0.9474 - val_loss: 0.2192 - val_accuracy: 0.6859\n",
            "Epoch 40/100\n",
            "68/68 [==============================] - 8s 124ms/step - loss: 0.0239 - accuracy: 0.9496 - val_loss: 0.2170 - val_accuracy: 0.6920\n",
            "Epoch 41/100\n",
            "68/68 [==============================] - 8s 125ms/step - loss: 0.0213 - accuracy: 0.9555 - val_loss: 0.2244 - val_accuracy: 0.6867\n",
            "Epoch 42/100\n",
            "68/68 [==============================] - 8s 124ms/step - loss: 0.0201 - accuracy: 0.9584 - val_loss: 0.2204 - val_accuracy: 0.6910\n",
            "Epoch 43/100\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.0186 - accuracy: 0.9632 - val_loss: 0.2299 - val_accuracy: 0.6947\n",
            "Epoch 44/100\n",
            "68/68 [==============================] - 9s 128ms/step - loss: 0.0169 - accuracy: 0.9666 - val_loss: 0.2366 - val_accuracy: 0.6865\n",
            "Epoch 45/100\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.0152 - accuracy: 0.9708 - val_loss: 0.2392 - val_accuracy: 0.6866\n",
            "Epoch 46/100\n",
            "68/68 [==============================] - 8s 125ms/step - loss: 0.0144 - accuracy: 0.9726 - val_loss: 0.2442 - val_accuracy: 0.6910\n",
            "Epoch 47/100\n",
            "68/68 [==============================] - 8s 124ms/step - loss: 0.0135 - accuracy: 0.9742 - val_loss: 0.2534 - val_accuracy: 0.6918\n",
            "Epoch 48/100\n",
            "68/68 [==============================] - 8s 125ms/step - loss: 0.0129 - accuracy: 0.9757 - val_loss: 0.2645 - val_accuracy: 0.6805\n",
            "Epoch 49/100\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.0118 - accuracy: 0.9782 - val_loss: 0.2653 - val_accuracy: 0.6851\n",
            "Epoch 50/100\n",
            "68/68 [==============================] - 8s 124ms/step - loss: 0.0112 - accuracy: 0.9796 - val_loss: 0.2697 - val_accuracy: 0.6861\n",
            "Epoch 51/100\n",
            "68/68 [==============================] - 9s 127ms/step - loss: 0.0105 - accuracy: 0.9809 - val_loss: 0.2732 - val_accuracy: 0.6839\n",
            "Epoch 52/100\n",
            "68/68 [==============================] - 8s 124ms/step - loss: 0.0097 - accuracy: 0.9822 - val_loss: 0.2748 - val_accuracy: 0.6888\n",
            "Epoch 53/100\n",
            "68/68 [==============================] - 9s 126ms/step - loss: 0.0093 - accuracy: 0.9831 - val_loss: 0.2796 - val_accuracy: 0.6895\n",
            "Epoch 54/100\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.0088 - accuracy: 0.9843 - val_loss: 0.2813 - val_accuracy: 0.6888\n",
            "Epoch 55/100\n",
            "68/68 [==============================] - 9s 125ms/step - loss: 0.0076 - accuracy: 0.9871 - val_loss: 0.2854 - val_accuracy: 0.6904\n",
            "Epoch 56/100\n",
            "68/68 [==============================] - 8s 125ms/step - loss: 0.0076 - accuracy: 0.9865 - val_loss: 0.2915 - val_accuracy: 0.6898\n",
            "Epoch 57/100\n",
            "68/68 [==============================] - 9s 126ms/step - loss: 0.0071 - accuracy: 0.9879 - val_loss: 0.2954 - val_accuracy: 0.6832\n",
            "Epoch 58/100\n",
            "68/68 [==============================] - 9s 126ms/step - loss: 0.0067 - accuracy: 0.9891 - val_loss: 0.2959 - val_accuracy: 0.6921\n",
            "Epoch 59/100\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.0064 - accuracy: 0.9889 - val_loss: 0.3011 - val_accuracy: 0.6919\n",
            "Epoch 60/100\n",
            "68/68 [==============================] - 8s 119ms/step - loss: 0.0057 - accuracy: 0.9905 - val_loss: 0.3087 - val_accuracy: 0.6838\n",
            "Epoch 61/100\n",
            "68/68 [==============================] - 9s 122ms/step - loss: 0.0053 - accuracy: 0.9913 - val_loss: 0.3165 - val_accuracy: 0.6912\n",
            "Epoch 62/100\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.0057 - accuracy: 0.9904 - val_loss: 0.3119 - val_accuracy: 0.6920\n",
            "Epoch 63/100\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.3160 - val_accuracy: 0.6922\n",
            "Epoch 64/100\n",
            "68/68 [==============================] - 8s 125ms/step - loss: 0.0050 - accuracy: 0.9914 - val_loss: 0.3159 - val_accuracy: 0.6926\n",
            "Epoch 65/100\n",
            "68/68 [==============================] - 8s 125ms/step - loss: 0.0047 - accuracy: 0.9918 - val_loss: 0.3213 - val_accuracy: 0.6922\n",
            "Epoch 66/100\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.0047 - accuracy: 0.9916 - val_loss: 0.3153 - val_accuracy: 0.6940\n",
            "Epoch 67/100\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.0045 - accuracy: 0.9926 - val_loss: 0.3254 - val_accuracy: 0.6916\n",
            "Epoch 68/100\n",
            "68/68 [==============================] - 8s 125ms/step - loss: 0.0043 - accuracy: 0.9928 - val_loss: 0.3305 - val_accuracy: 0.6917\n",
            "Epoch 69/100\n",
            "68/68 [==============================] - 9s 126ms/step - loss: 0.0039 - accuracy: 0.9935 - val_loss: 0.3341 - val_accuracy: 0.6917\n",
            "Epoch 70/100\n",
            "68/68 [==============================] - 8s 114ms/step - loss: 0.0036 - accuracy: 0.9941 - val_loss: 0.3400 - val_accuracy: 0.6933\n",
            "Epoch 71/100\n",
            "68/68 [==============================] - 8s 113ms/step - loss: 0.0035 - accuracy: 0.9942 - val_loss: 0.3386 - val_accuracy: 0.6948\n",
            "Epoch 72/100\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.0035 - accuracy: 0.9940 - val_loss: 0.3399 - val_accuracy: 0.6931\n",
            "Epoch 73/100\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.0035 - accuracy: 0.9938 - val_loss: 0.3408 - val_accuracy: 0.6949\n",
            "Epoch 74/100\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.0034 - accuracy: 0.9942 - val_loss: 0.3447 - val_accuracy: 0.6933\n",
            "Epoch 75/100\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.0033 - accuracy: 0.9938 - val_loss: 0.3458 - val_accuracy: 0.6935\n",
            "Epoch 76/100\n",
            "68/68 [==============================] - 8s 124ms/step - loss: 0.0031 - accuracy: 0.9950 - val_loss: 0.3530 - val_accuracy: 0.6906\n",
            "Epoch 77/100\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.0032 - accuracy: 0.9945 - val_loss: 0.3474 - val_accuracy: 0.6969\n",
            "Epoch 78/100\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.0032 - accuracy: 0.9948 - val_loss: 0.3501 - val_accuracy: 0.6972\n",
            "Epoch 79/100\n",
            "68/68 [==============================] - 8s 125ms/step - loss: 0.0028 - accuracy: 0.9955 - val_loss: 0.3524 - val_accuracy: 0.6937\n",
            "Epoch 80/100\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.0029 - accuracy: 0.9949 - val_loss: 0.3558 - val_accuracy: 0.6932\n",
            "Epoch 81/100\n",
            "68/68 [==============================] - 9s 126ms/step - loss: 0.0027 - accuracy: 0.9952 - val_loss: 0.3580 - val_accuracy: 0.6926\n",
            "Epoch 82/100\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.0028 - accuracy: 0.9951 - val_loss: 0.3582 - val_accuracy: 0.6952\n",
            "Epoch 83/100\n",
            "68/68 [==============================] - 8s 125ms/step - loss: 0.0025 - accuracy: 0.9960 - val_loss: 0.3633 - val_accuracy: 0.6921\n",
            "Epoch 84/100\n",
            "68/68 [==============================] - 9s 126ms/step - loss: 0.0028 - accuracy: 0.9952 - val_loss: 0.3615 - val_accuracy: 0.6898\n",
            "Epoch 85/100\n",
            "68/68 [==============================] - 9s 126ms/step - loss: 0.0026 - accuracy: 0.9957 - val_loss: 0.3620 - val_accuracy: 0.6985\n",
            "Epoch 86/100\n",
            "68/68 [==============================] - 8s 122ms/step - loss: 0.0024 - accuracy: 0.9959 - val_loss: 0.3620 - val_accuracy: 0.6959\n",
            "Epoch 87/100\n",
            "68/68 [==============================] - 8s 125ms/step - loss: 0.0026 - accuracy: 0.9957 - val_loss: 0.3670 - val_accuracy: 0.6933\n",
            "Epoch 88/100\n",
            "68/68 [==============================] - 8s 124ms/step - loss: 0.0023 - accuracy: 0.9959 - val_loss: 0.3650 - val_accuracy: 0.6929\n",
            "Epoch 89/100\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.0025 - accuracy: 0.9954 - val_loss: 0.3716 - val_accuracy: 0.6944\n",
            "Epoch 90/100\n",
            "68/68 [==============================] - 8s 124ms/step - loss: 0.0023 - accuracy: 0.9961 - val_loss: 0.3663 - val_accuracy: 0.6986\n",
            "Epoch 91/100\n",
            "68/68 [==============================] - 8s 124ms/step - loss: 0.0022 - accuracy: 0.9963 - val_loss: 0.3766 - val_accuracy: 0.6966\n",
            "Epoch 92/100\n",
            "68/68 [==============================] - 9s 126ms/step - loss: 0.0021 - accuracy: 0.9962 - val_loss: 0.3712 - val_accuracy: 0.6978\n",
            "Epoch 93/100\n",
            "68/68 [==============================] - 8s 121ms/step - loss: 0.0022 - accuracy: 0.9964 - val_loss: 0.3724 - val_accuracy: 0.6963\n",
            "Epoch 94/100\n",
            "68/68 [==============================] - 9s 126ms/step - loss: 0.0020 - accuracy: 0.9966 - val_loss: 0.3769 - val_accuracy: 0.6921\n",
            "Epoch 95/100\n",
            "68/68 [==============================] - 9s 129ms/step - loss: 0.0020 - accuracy: 0.9965 - val_loss: 0.3770 - val_accuracy: 0.6957\n",
            "Epoch 96/100\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.0020 - accuracy: 0.9965 - val_loss: 0.3755 - val_accuracy: 0.6963\n",
            "Epoch 97/100\n",
            "68/68 [==============================] - 8s 124ms/step - loss: 0.0019 - accuracy: 0.9967 - val_loss: 0.3801 - val_accuracy: 0.6974\n",
            "Epoch 98/100\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.0019 - accuracy: 0.9969 - val_loss: 0.3779 - val_accuracy: 0.6963\n",
            "Epoch 99/100\n",
            "68/68 [==============================] - 8s 124ms/step - loss: 0.0020 - accuracy: 0.9965 - val_loss: 0.3802 - val_accuracy: 0.6942\n",
            "Epoch 100/100\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 0.0018 - accuracy: 0.9968 - val_loss: 0.3815 - val_accuracy: 0.6957\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f74f074afd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gTvz5CPGe0Or"
      },
      "source": [
        "model.save_weights('nmt_weights_100epochs.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FylnSvv9e0Or"
      },
      "source": [
        "model.load_weights('nmt_weights_100epochs.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nwkJ2Cpce0Os"
      },
      "source": [
        "# Encode the input sequence to get the \"Context vectors\"\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_state_input = [decoder_state_input_h, decoder_state_input_c]\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_state_input)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_state_input,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Vmtulb5ie0Os"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of \n",
        "    #target sequence with the start character.\n",
        "    target_seq[0, 0] = target_word2idx['start_']\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)# Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_word =target_idx2word[sampled_token_index]\n",
        "        decoded_sentence += ' '+ sampled_word\n",
        "        #print(sampled_word)\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_word == '_end' or len(decoded_sentence) > max_target_length):\n",
        "            stop_condition = True\n",
        "            # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b4ChDrTte0Os"
      },
      "source": [
        "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
        "i=-1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uBVMcR3Le0Os",
        "outputId": "f199c8af-6e62-4ae1-cf75-56628eb51dbe"
      },
      "source": [
        "i+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input Source sentence:', X_train[i:i+1].values[0])\n",
        "print('Actual Target Translation:', y_train[i:i+1].values[0][6:-4])\n",
        "print('Predicted Target Translation:', decoded_sentence[:-4])\n",
        "#print(input_seq, actual_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Source sentence: အောင်ဆန်း ၏ မိခင် မျိုးရိုး ထဲ တွင် ရာထူး ကြီး မင်းမှုထမ်း အချို့ ပါဝင် ခဲ့ ပါ သည် ။\n",
            "Actual Target Translation:  n ppm n n ppm ppm n adj n adj v part part ppm punc \n",
            "Predicted Target Translation:  n ppm n n ppm ppm n adj n adj v part part ppm punc \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwaQ4DSlPZRK"
      },
      "source": [
        "dev_gen = generate_batch(X_dev,y_dev,batch_size=1)\n",
        "\n",
        "dev_set = pd.DataFrame(columns=['source','ref','hyp'])\n",
        "for k in range(len(X_dev)):\n",
        "  if(k%100==0):\n",
        "    print(k)\n",
        "  (input_seq, actual_output),_ = next(dev_gen)\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  dev_set = dev_set.append({'source':X_dev[k:k+1].values[0],\n",
        "                            'ref':y_dev[k:k+1].values[0][6:-4],\n",
        "                            'hyp':decoded_sentence[:-4]},ignore_index = True)\n",
        "  \"\"\"print('Input Source sentence:', X_dev[k:k+1].values[0])\n",
        "  print('Actual Target Translation:', y_dev[k:k+1].values[0][6:-4])\n",
        "  print('Predicted Target Translation:', decoded_sentence[:-4])\n",
        "  print()\"\"\"\n",
        "dev_set.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgz1yPFMkxJ0"
      },
      "source": [
        "dev_set.to_csv('THN_dev_set.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irDhjf5ulA_M"
      },
      "source": [
        "dev_BLEU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiRvIQDFe0Ot"
      },
      "source": [
        "test_gen = generate_batch(X_test, y_test, batch_size = 1)\n",
        "k=-1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48ss1ua3Wcsg"
      },
      "source": [
        "test_gen = generate_batch(X_test, y_test, batch_size = 1)\n",
        "\n",
        "test_set = pd.DataFrame(columns=['source','ref','hyp'])\n",
        "for k in range(len(X_test)):\n",
        "  if(k%100==0):\n",
        "    print(k)\n",
        "  (input_seq, actual_output),_ = next(test_gen)\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  test_set = test_set.append({'source':X_test[k:k+1].values[0],\n",
        "                            'ref':y_test[k:k+1].values[0][6:-4],\n",
        "                            'hyp':decoded_sentence[:-4]},ignore_index = True)\n",
        "  \"\"\"print('Input Source sentence:', X_dev[k:k+1].values[0])\n",
        "  print('Actual Target Translation:', y_dev[k:k+1].values[0][6:-4])\n",
        "  print('Predicted Target Translation:', decoded_sentence[:-4])\n",
        "  print()\"\"\"\n",
        "test_set.head()\n",
        "test_set.to_csv(\"THN_test_set.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}